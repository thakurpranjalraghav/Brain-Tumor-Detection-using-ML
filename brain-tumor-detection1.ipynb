{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T15:31:02.015193600Z",
     "start_time": "2023-12-03T15:31:01.870453500Z"
    },
    "execution": {
     "iopub.execute_input": "2021-06-15T20:39:16.984379Z",
     "iopub.status.busy": "2021-06-15T20:39:16.983861Z",
     "iopub.status.idle": "2021-06-15T20:39:18.030853Z",
     "shell.execute_reply": "2021-06-15T20:39:18.029858Z",
     "shell.execute_reply.started": "2021-06-15T20:39:16.984347Z"
    }
   },
   "outputs": [],
   "source": [
    "##%% IMPORTING LIBRARIES\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import random\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import zipfile\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T15:31:03.187448500Z",
     "start_time": "2023-12-03T15:31:01.874555100Z"
    },
    "execution": {
     "iopub.execute_input": "2021-06-15T20:39:18.034121Z",
     "iopub.status.busy": "2021-06-15T20:39:18.033609Z",
     "iopub.status.idle": "2021-06-15T20:39:18.347329Z",
     "shell.execute_reply": "2021-06-15T20:39:18.346414Z",
     "shell.execute_reply.started": "2021-06-15T20:39:18.034054Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>archive/no\\no0.jpg</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>archive/no\\no1.jpg</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>archive/no\\no10.jpg</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>archive/no\\no100.jpg</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>archive/no\\no1000.jpg</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   image    label\n",
       "0     archive/no\\no0.jpg  Healthy\n",
       "1     archive/no\\no1.jpg  Healthy\n",
       "2    archive/no\\no10.jpg  Healthy\n",
       "3   archive/no\\no100.jpg  Healthy\n",
       "4  archive/no\\no1000.jpg  Healthy"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##%% IMPORTING DATA\n",
    "\n",
    "def importing_data(path):\n",
    "    sample = []\n",
    "    for filename in glob.glob(path):\n",
    "        #img = Image.open(filename,'r')\n",
    "        #IMG = np.array(img)\n",
    "        sample.append(filename)\n",
    "    return sample\n",
    "\n",
    "path1 = 'archive/no/*.jpg'\n",
    "path2 = 'archive/yes/*.jpg'\n",
    "path3 = 'archive/pred/*.jpg'\n",
    "path4 = 'archive/xyz/*.jpg'\n",
    "train_n = importing_data(path1)\n",
    "train_y = importing_data(path2)\n",
    "test = importing_data(path3)\n",
    "xyz_test = importing_data(path4)\n",
    "\n",
    "##%% CREATION OF DATASETS\n",
    "\n",
    "df_train_n = pd.DataFrame({'image':train_n, 'label': 'Healthy'})\n",
    "df_train_y = pd.DataFrame({'image':train_y, 'label': 'Affected'})\n",
    "df_test = pd.DataFrame({'image':test})\n",
    "xyz_test=pd.DataFrame({'image':xyz_test})\n",
    "train_data = pd.concat([df_train_n, df_train_y])\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T15:31:03.641191200Z",
     "start_time": "2023-12-03T15:31:03.162647600Z"
    },
    "execution": {
     "iopub.execute_input": "2021-06-15T20:39:18.351351Z",
     "iopub.status.busy": "2021-06-15T20:39:18.351006Z",
     "iopub.status.idle": "2021-06-15T20:39:18.482499Z",
     "shell.execute_reply": "2021-06-15T20:39:18.481515Z",
     "shell.execute_reply.started": "2021-06-15T20:39:18.351322Z"
    }
   },
   "outputs": [],
   "source": [
    "##%% TRAIN-VALIDATION SPLIT (90% TRAIN - 10% VALIDATION)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val = train_test_split(train_data,\n",
    "                                  test_size = 0.1,\n",
    "                                  shuffle = True,\n",
    "                                  random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"subsection-one\"></a>\n",
    "### CREATING THE CNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T15:31:13.180314100Z",
     "start_time": "2023-12-03T15:31:03.469104200Z"
    },
    "execution": {
     "iopub.execute_input": "2021-06-15T20:39:18.485314Z",
     "iopub.status.busy": "2021-06-15T20:39:18.485005Z",
     "iopub.status.idle": "2021-06-15T20:39:27.719140Z",
     "shell.execute_reply": "2021-06-15T20:39:27.717561Z",
     "shell.execute_reply.started": "2021-06-15T20:39:18.485283Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\miniconda3\\envs\\detect\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,664</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">204,928</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">409,728</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">819,456</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">147,520</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m1,664\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │         \u001b[38;5;34m204,928\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │         \u001b[38;5;34m409,728\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │         \u001b[38;5;34m819,456\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │         \u001b[38;5;34m147,520\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │              \u001b[38;5;34m66\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,585,442</span> (6.05 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,585,442\u001b[0m (6.05 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,585,442</span> (6.05 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,585,442\u001b[0m (6.05 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##%% CREATING THE CNN MODEL \n",
    "\n",
    "import keras\n",
    "from keras.metrics import AUC, Recall, Precision\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout, Conv2D , MaxPooling2D, Flatten\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "def build_model():\n",
    "    \n",
    "    '''Sequential Model creation'''\n",
    "    Cnn = Sequential()\n",
    "    \n",
    "    Cnn.add(Conv2D(64,(5,5), activation = 'relu', padding = 'same',\n",
    "                   strides=(2,2), input_shape = [224,224,1]))\n",
    "    Cnn.add(MaxPooling2D(2))\n",
    "    Cnn.add(Conv2D(128,(5,5), activation = 'relu', padding = 'same', strides=(2,2)))\n",
    "    Cnn.add(Conv2D(128,(5,5), activation = 'relu', padding = 'same', strides=(2,2)))\n",
    "    Cnn.add(Conv2D(256,(5,5), activation = 'relu', padding = 'same', strides=(2,2)))\n",
    "    Cnn.add(MaxPooling2D(2))\n",
    "    #Cnn.add(GlobalAveragePooling2D())\n",
    "    Cnn.add(Flatten())\n",
    "    Cnn.add(Dense(64, activation = 'relu'))\n",
    "    Cnn.add(Dropout(0.4))\n",
    "    Cnn.add(Dense(32, activation = 'relu'))\n",
    "    Cnn.add(Dropout(0.4))\n",
    "    Cnn.add(Dense(2, activation = 'softmax'))\n",
    "    \n",
    "    return Cnn\n",
    "\n",
    "keras_model = build_model()\n",
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T15:31:13.180314100Z",
     "start_time": "2023-12-03T15:31:13.176806800Z"
    },
    "execution": {
     "iopub.execute_input": "2021-06-15T20:39:27.723819Z",
     "iopub.status.busy": "2021-06-15T20:39:27.723478Z",
     "iopub.status.idle": "2021-06-15T20:39:27.735496Z",
     "shell.execute_reply": "2021-06-15T20:39:27.734540Z",
     "shell.execute_reply.started": "2021-06-15T20:39:27.723757Z"
    }
   },
   "outputs": [],
   "source": [
    "##%% FITTING THE MODEL\n",
    "\n",
    "def Model_fit(train_data, val_data):\n",
    "    \n",
    "    keras_model = None\n",
    "    \n",
    "    keras_model = build_model()\n",
    "    \n",
    "    '''Compiling the model'''\n",
    "    \n",
    "    keras_model.compile(optimizer = RMSprop(learning_rate = 1e-4),\n",
    "                        loss='sparse_categorical_crossentropy',\n",
    "                        metrics =['acc'])\n",
    "    \n",
    "    es = EarlyStopping(monitor='val_loss', mode='min',\n",
    "                       patience=2,\n",
    "                       restore_best_weights=True,\n",
    "                       verbose=1)\n",
    "                       \n",
    "    \n",
    "    checkpoint_cb = ModelCheckpoint(\"Brain_model_best.keras\",\n",
    "                                    save_best_only=True)\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(monitor = 'val_loss',\n",
    "                                  factor = 0.2,\n",
    "                                  patience = 3,\n",
    "                                  min_lr = 1e-5,\n",
    "                                  mode = 'min',\n",
    "                                  verbose=1)\n",
    "                                  \n",
    "    \n",
    "    history = keras_model.fit(train_data,\n",
    "                              validation_data = val_data,\n",
    "                              epochs= 1,\n",
    "                              batch_size = 10,\n",
    "                              callbacks=[es, checkpoint_cb, reduce_lr])\n",
    "                              \n",
    "    \n",
    "      \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T15:41:00.813539100Z",
     "start_time": "2023-12-03T15:31:13.180314100Z"
    },
    "execution": {
     "iopub.execute_input": "2021-06-15T20:39:27.738978Z",
     "iopub.status.busy": "2021-06-15T20:39:27.738608Z",
     "iopub.status.idle": "2021-06-15T20:48:02.697599Z",
     "shell.execute_reply": "2021-06-15T20:48:02.696059Z",
     "shell.execute_reply.started": "2021-06-15T20:39:27.738947Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 validated image filenames belonging to 0 classes.\n",
      "Found 0 validated image filenames belonging to 0 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\miniconda3\\envs\\detect\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:920: UserWarning: Found 2700 invalid image filename(s) in x_col=\"image\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\miniconda3\\envs\\detect\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:920: UserWarning: Found 300 invalid image filename(s) in x_col=\"image\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\miniconda3\\envs\\detect\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on Fold:  1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Must provide at least one structure",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 43\u001b[0m\n\u001b[0;32m     39\u001b[0m         cv_histories\u001b[38;5;241m.\u001b[39mappend(Model_fit(train_set, val_set))\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cv_histories\n\u001b[1;32m---> 43\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m CV_training(X_train,X_val)\n",
      "Cell \u001b[1;32mIn[7], line 39\u001b[0m, in \u001b[0;36mCV_training\u001b[1;34m(train_data, val_data)\u001b[0m\n\u001b[0;32m     27\u001b[0m     val_set \u001b[38;5;241m=\u001b[39m datagen\u001b[38;5;241m.\u001b[39mflow_from_dataframe(val_data,\n\u001b[0;32m     28\u001b[0m                                           directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124marchive/RCNN/VAL/*.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     29\u001b[0m                                           x_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     35\u001b[0m                                           shuffle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     36\u001b[0m                                           interpolation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbilinear\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining on Fold: \u001b[39m\u001b[38;5;124m\"\u001b[39m,i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 39\u001b[0m     cv_histories\u001b[38;5;241m.\u001b[39mappend(Model_fit(train_set, val_set))\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_histories\n",
      "Cell \u001b[1;32mIn[5], line 32\u001b[0m, in \u001b[0;36mModel_fit\u001b[1;34m(train_data, val_data)\u001b[0m\n\u001b[0;32m     21\u001b[0m checkpoint_cb \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBrain_model_best.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     22\u001b[0m                                 save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     24\u001b[0m reduce_lr \u001b[38;5;241m=\u001b[39m ReduceLROnPlateau(monitor \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     25\u001b[0m                               factor \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m,\n\u001b[0;32m     26\u001b[0m                               patience \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m     27\u001b[0m                               min_lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-5\u001b[39m,\n\u001b[0;32m     28\u001b[0m                               mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     29\u001b[0m                               verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 32\u001b[0m history \u001b[38;5;241m=\u001b[39m keras_model\u001b[38;5;241m.\u001b[39mfit(train_data,\n\u001b[0;32m     33\u001b[0m                           validation_data \u001b[38;5;241m=\u001b[39m val_data,\n\u001b[0;32m     34\u001b[0m                           epochs\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     35\u001b[0m                           batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m     36\u001b[0m                           callbacks\u001b[38;5;241m=\u001b[39m[es, checkpoint_cb, reduce_lr])\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\detect\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\detect\\Lib\\site-packages\\keras\\src\\utils\\tree.py:236\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structures)\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`func` must be callable. Received: func=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m structures:\n\u001b[1;32m--> 236\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust provide at least one structure\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m other \u001b[38;5;129;01min\u001b[39;00m structures[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[0;32m    238\u001b[0m     assert_same_structure(structures[\u001b[38;5;241m0\u001b[39m], other, check_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mValueError\u001b[0m: Must provide at least one structure"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "k_fold = 3\n",
    "IMG_SIZE = 224\n",
    "size = (IMG_SIZE,IMG_SIZE)\n",
    "n_CLASS = 2\n",
    "\n",
    "def CV_training(train_data, val_data):\n",
    "    \n",
    "    cv_histories = []\n",
    "    \n",
    "    for i in range(0,k_fold):\n",
    "    \n",
    "        datagen = ImageDataGenerator(rescale = 1./255)\n",
    "    \n",
    "        train_set = datagen.flow_from_dataframe(train_data,\n",
    "                                                directory = 'archive/RCNN/TRAIN/*.jpg',\n",
    "                                                x_col = 'image',\n",
    "                                                y_col = 'label',\n",
    "                                                target_size = size,\n",
    "                                                color_mode = 'grayscale',\n",
    "                                                class_mode = 'sparse',\n",
    "                                                batch_size = 10,\n",
    "                                                shuffle = True,\n",
    "                                                interpolation = 'bilinear')\n",
    "        \n",
    "        val_set = datagen.flow_from_dataframe(val_data,\n",
    "                                              directory = 'archive/RCNN/VAL/*.jpg',\n",
    "                                              x_col = 'image',\n",
    "                                              y_col = 'label',\n",
    "                                              target_size = size,\n",
    "                                              color_mode = 'grayscale',\n",
    "                                              class_mode = 'sparse',\n",
    "                                              batch_size = 10,\n",
    "                                              shuffle = True,\n",
    "                                              interpolation = 'bilinear')\n",
    "        print(\"Training on Fold: \",i+1)\n",
    "    \n",
    "        cv_histories.append(Model_fit(train_set, val_set))\n",
    "    \n",
    "    return cv_histories\n",
    "\n",
    "cv_results = CV_training(X_train,X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Sequential\n",
    "\n",
    "k_fold = 3\n",
    "IMG_SIZE = 224\n",
    "size = (IMG_SIZE, IMG_SIZE)\n",
    "n_CLASS = 2\n",
    "\n",
    "def Model_fit(train_data, val_data):\n",
    "    keras_model = Sequential()\n",
    "    # Define your model architecture here\n",
    "    # Example architecture:\n",
    "    # keras_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "    # keras_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # keras_model.add(Flatten())\n",
    "    # keras_model.add(Dense(128, activation='relu'))\n",
    "    # keras_model.add(Dense(n_CLASS, activation='softmax'))\n",
    "\n",
    "    keras_model.compile(optimizer=RMSprop(learning_rate=1e-4),\n",
    "                        loss='sparse_categorical_crossentropy',\n",
    "                        metrics=['acc'])\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min',\n",
    "                       patience=2,\n",
    "                       restore_best_weights=True,\n",
    "                       verbose=1)\n",
    "\n",
    "    checkpoint_cb = ModelCheckpoint(\"Brain_model_best.keras\",\n",
    "                                    save_best_only=True)\n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                  factor=0.2,\n",
    "                                  patience=3,\n",
    "                                  min_lr=1e-5,\n",
    "                                  mode='min',\n",
    "                                  verbose=1)\n",
    "\n",
    "    history = keras_model.fit(train_data,\n",
    "                              validation_data=val_data,\n",
    "                              epochs=50,\n",
    "                              batch_size=10,\n",
    "                              callbacks=[es, checkpoint_cb, reduce_lr])\n",
    "\n",
    "    return history\n",
    "\n",
    "def CV_training(train_data, val_data):\n",
    "    cv_histories = []\n",
    "\n",
    "    for i in range(k_fold):\n",
    "        datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "        train_set = datagen.flow_from_dataframe(dataframe=train_data,\n",
    "                                                directory='archive/RCNN/TRAIN',\n",
    "                                                x_col='image',\n",
    "                                                y_col='label',\n",
    "                                                target_size=size,\n",
    "                                                color_mode='grayscale',\n",
    "                                                class_mode='sparse',\n",
    "                                                batch_size=10,\n",
    "                                                shuffle=True,\n",
    "                                                interpolation='bilinear')\n",
    "\n",
    "        val_set = datagen.flow_from_dataframe(dataframe=val_data,\n",
    "                                              directory='archive/RCNN/VAL',\n",
    "                                              x_col='image',\n",
    "                                              y_col='label',\n",
    "                                              target_size=size,\n",
    "                                              color_mode='grayscale',\n",
    "                                              class_mode='sparse',\n",
    "                                              batch_size=10,\n",
    "                                              shuffle=True,\n",
    "                                              interpolation='bilinear')\n",
    "\n",
    "        print(\"Training on Fold:\", i + 1)\n",
    "        # Add error checking for empty data\n",
    "        if train_set.samples == 0 or val_set.samples == 0:\n",
    "            print(\"Error: Empty data in fold\", i + 1)\n",
    "            continue\n",
    "\n",
    "        cv_histories.append(Model_fit(train_set, val_set))\n",
    "\n",
    "    return cv_histories\n",
    "\n",
    "# Check if X_train and X_val have data\n",
    "if X_train.empty or X_val.empty:\n",
    "    print(\"Error: Empty data in X_train or X_val\")\n",
    "else:\n",
    "    cv_results = CV_training(X_train, X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def count_images_in_folder(folder_path):\n",
    "    # Check if the folder path exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"Folder '{folder_path}' does not exist.\")\n",
    "        return\n",
    "\n",
    "    # Initialize a counter for the number of images\n",
    "    image_count = 0\n",
    "\n",
    "    # Iterate through all files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        # Check if the file is an image based on its extension\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n",
    "            image_count += 1\n",
    "\n",
    "    return image_count\n",
    "\n",
    "# Specify the folder path you want to count images in\n",
    "folder_path = 'archive/RCNN/TRAIN'\n",
    "\n",
    "# Call the function to count images in the folder\n",
    "num_images = count_images_in_folder(folder_path)\n",
    "\n",
    "if num_images is not None:\n",
    "    print(f\"Found {num_images} images in the folder '{folder_path}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "k_fold = 3\n",
    "IMG_SIZE = 224\n",
    "size = (IMG_SIZE, IMG_SIZE)\n",
    "n_CLASS = 2\n",
    "\n",
    "def load_images_and_labels(dataframe, directory):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for index, row in dataframe.iterrows():\n",
    "        image_path = os.path.join(directory, row['image'])\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        image = cv2.resize(image, size, interpolation=cv2.INTER_LINEAR)\n",
    "        images.append(image)\n",
    "        labels.append(row['label'])\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    return images, labels\n",
    "\n",
    "def CV_training(train_data, val_data):\n",
    "    cv_histories = []\n",
    "    \n",
    "    for i in range(0, k_fold):\n",
    "        train_images, train_labels = load_images_and_labels(train_data, 'archive/RCNN/TRAIN/')\n",
    "        val_images, val_labels = load_images_and_labels(val_data, 'archive/RCNN/VAL/')\n",
    "        \n",
    "        train_images = train_images / 255.0\n",
    "        val_images = val_images / 255.0\n",
    "        \n",
    "        print(\"Training on Fold: \", i + 1)\n",
    "        cv_histories.append(Model_fit(train_images, train_labels, val_images, val_labels))\n",
    "    \n",
    "    return cv_histories\n",
    "\n",
    "cv_results = CV_training(X_train, X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def check_path_validity(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"Path '{file_path}' exists.\")\n",
    "        if os.path.isfile(file_path):\n",
    "            print(f\"'{file_path}' is a valid file path.\")\n",
    "        else:\n",
    "            print(f\"'{file_path}' is not a file path.\")\n",
    "    else:\n",
    "        print(f\"Path '{file_path}' does not exist.\")\n",
    "\n",
    "# Example usage\n",
    "file_path = 'archive/RCNN/TRAIN'\n",
    "check_path_validity(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T15:41:00.813539100Z",
     "start_time": "2023-12-03T15:41:00.807304100Z"
    },
    "execution": {
     "iopub.execute_input": "2021-06-15T20:48:02.700274Z",
     "iopub.status.busy": "2021-06-15T20:48:02.699843Z",
     "iopub.status.idle": "2021-06-15T20:48:02.710044Z",
     "shell.execute_reply": "2021-06-15T20:48:02.708201Z",
     "shell.execute_reply.started": "2021-06-15T20:48:02.700224Z"
    }
   },
   "outputs": [],
   "source": [
    "##%% CHEKING THE CROSS VALIDATION METRICS\n",
    "\n",
    "def acc_results(results):\n",
    "    i = 0\n",
    "    for fold in cv_results:\n",
    "        print('Val_Acc Folder '+ str(i) + ' =', max(fold.history['val_acc']))\n",
    "        i += 1\n",
    "        \n",
    "acc_results(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T15:41:02.478331800Z",
     "start_time": "2023-12-03T15:41:00.820570300Z"
    },
    "execution": {
     "iopub.execute_input": "2021-06-15T20:48:02.714474Z",
     "iopub.status.busy": "2021-06-15T20:48:02.713948Z",
     "iopub.status.idle": "2021-06-15T20:48:04.108365Z",
     "shell.execute_reply": "2021-06-15T20:48:04.107506Z",
     "shell.execute_reply.started": "2021-06-15T20:48:02.714407Z"
    }
   },
   "outputs": [],
   "source": [
    "##%% LOOKING AT THE ACCURACY-LOSS PLOTS FOR EACH FOLD\n",
    "\n",
    "def Acc_Loss_Plot(results):\n",
    "    \n",
    "    for fold in results:\n",
    "        \n",
    "        acc = fold.history['acc']\n",
    "        val_acc = fold.history['val_acc']\n",
    "        loss = fold.history['loss']\n",
    "        val_loss = fold.history['val_loss']\n",
    "    \n",
    "        fig, (ax1, ax2) = plt.subplots(1,2, figsize= (10,5))\n",
    "        fig.suptitle(\" MODEL'S METRICS VISUALIZATION \")\n",
    "\n",
    "        ax1.plot(range(1, len(acc) + 1), acc)\n",
    "        ax1.plot(range(1, len(val_acc) + 1), val_acc)\n",
    "        ax1.set_title('History of Accuracy')\n",
    "        ax1.set_xlabel('Epochs')\n",
    "        ax1.set_ylabel('Accuracy')\n",
    "        ax1.legend(['training', 'validation'])\n",
    "\n",
    "\n",
    "        ax2.plot(range(1, len(loss) + 1), loss)\n",
    "        ax2.plot(range(1, len(val_loss) + 1), val_loss)\n",
    "        ax2.set_title('History of Loss')\n",
    "        ax2.set_xlabel('Epochs')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.legend(['training', 'validation'])\n",
    "        plt.show()\n",
    "    \n",
    "Acc_Loss_Plot(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T15:41:03.114905700Z",
     "start_time": "2023-12-03T15:41:02.463322800Z"
    },
    "execution": {
     "iopub.execute_input": "2021-06-15T20:48:04.112042Z",
     "iopub.status.busy": "2021-06-15T20:48:04.111579Z",
     "iopub.status.idle": "2021-06-15T20:48:05.147136Z",
     "shell.execute_reply": "2021-06-15T20:48:05.146115Z",
     "shell.execute_reply.started": "2021-06-15T20:48:04.112001Z"
    }
   },
   "outputs": [],
   "source": [
    "##%% LOADING THE MODEL\n",
    "\n",
    "import keras\n",
    "\n",
    "keras_model = keras.models.load_model('Brain_model_best.h5')\n",
    "keras_model.compile(optimizer = RMSprop(learning_rate = 1e-4),\n",
    "                    loss='sparse_categorical_crossentropy', metrics =[ 'acc'])\n",
    "\n",
    "# Predictions on the test set\n",
    "\n",
    "datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "test_set = datagen.flow_from_dataframe(df_test,\n",
    "                                       directory = 'C:/vansh/programming/project/python/archive/Br35H-Mask-RCNN/TEST/*.jpg',\n",
    "                                       x_col = 'image',\n",
    "                                       y_col = None,\n",
    "                                       target_size = size,\n",
    "                                       color_mode = 'grayscale',\n",
    "                                       class_mode = None,\n",
    "                                       batch_size = 10,\n",
    "                                       shuffle = False,\n",
    "                                       interpolation = 'bilinear')\n",
    "\n",
    "predictions = keras_model.predict(test_set)\n",
    "predictions = predictions.argmax(axis=-1)\n",
    "print(\"Where 0 = 'Affected'\")\n",
    "print(\"Where 1 = 'Healthy'\")\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T15:41:03.114905700Z",
     "start_time": "2023-12-03T15:41:03.114323200Z"
    },
    "execution": {
     "iopub.execute_input": "2021-06-15T20:48:05.151356Z",
     "iopub.status.busy": "2021-06-15T20:48:05.150989Z",
     "iopub.status.idle": "2021-06-15T20:48:05.159349Z",
     "shell.execute_reply": "2021-06-15T20:48:05.157548Z",
     "shell.execute_reply.started": "2021-06-15T20:48:05.151320Z"
    }
   },
   "outputs": [],
   "source": [
    "pred = []\n",
    "[pred.append('Healthy') if i == 1 else pred.append('Affected') for i in predictions]\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T15:41:04.257927300Z",
     "start_time": "2023-12-03T15:41:03.114905700Z"
    },
    "execution": {
     "iopub.execute_input": "2021-06-15T20:57:31.722404Z",
     "iopub.status.busy": "2021-06-15T20:57:31.721949Z",
     "iopub.status.idle": "2021-06-15T20:57:32.116951Z",
     "shell.execute_reply": "2021-06-15T20:57:32.115909Z",
     "shell.execute_reply.started": "2021-06-15T20:57:31.722361Z"
    }
   },
   "outputs": [],
   "source": [
    "##%% OBTAINING PREDICTIONS OF THE FIRST BATCH\n",
    "    \n",
    "images10 = [test_set[0][0],test_set[0][1],test_set[0][2],test_set[0][3],test_set[0][4],\n",
    "            test_set[0][5],test_set[0][6],test_set[0][7],test_set[0][8],test_set[0][9]]\n",
    "            \n",
    "prediction10 = pred[0:9]\n",
    "final_pred = zip(images10,prediction10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T15:41:05.966788400Z",
     "start_time": "2023-12-03T15:41:04.286802200Z"
    },
    "execution": {
     "iopub.execute_input": "2021-06-15T20:57:37.699233Z",
     "iopub.status.busy": "2021-06-15T20:57:37.698828Z",
     "iopub.status.idle": "2021-06-15T20:57:39.455659Z",
     "shell.execute_reply": "2021-06-15T20:57:39.454252Z",
     "shell.execute_reply.started": "2021-06-15T20:57:37.699199Z"
    }
   },
   "outputs": [],
   "source": [
    "def pre_visualization(data, predictions):\n",
    "    \n",
    "    for image,pred in final_pred:\n",
    "        plt.imshow(image.reshape(224,224), cmap = 'gray')\n",
    "        plt.title(\"Model's Prediction: \" + str(pred))\n",
    "        plt.show()\n",
    "        \n",
    "pre_visualization(images10,prediction10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T15:41:06.310994600Z",
     "start_time": "2023-12-03T15:41:05.966788400Z"
    }
   },
   "outputs": [],
   "source": [
    "keras_model = keras.models.load_model('Brain_model_best.h5')\n",
    "keras_model.compile(optimizer = RMSprop(learning_rate = 1e-4),\n",
    "                    loss='sparse_categorical_crossentropy', metrics =[ 'acc'])\n",
    "\n",
    "# Predictions on the test set\n",
    "\n",
    "datagen1 = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "xyz_set = datagen1.flow_from_dataframe(xyz_test,\n",
    "                                       directory = 'C:/vansh/programming/project/python/archive/Br35H-Mask-RCNN/xyz/y1.jpg',\n",
    "                                       x_col = 'image',\n",
    "                                       y_col = None,\n",
    "                                       target_size = size,\n",
    "                                       color_mode = 'grayscale',\n",
    "                                       class_mode = None,\n",
    "                                       batch_size = 10,\n",
    "                                       shuffle = False,\n",
    "                                       interpolation = 'bilinear')\n",
    "\n",
    "predictions1 = keras_model.predict(xyz_set)\n",
    "predictions1 = predictions1.argmax(axis=-1)\n",
    "print(\"Where 0 = 'Affected'\")\n",
    "print(\"Where 1 = 'Healthy'\")\n",
    "print(predictions1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T15:41:06.319883900Z",
     "start_time": "2023-12-03T15:41:06.319883900Z"
    }
   },
   "outputs": [],
   "source": [
    "pred1 = []\n",
    "[pred1.append('Healthy') if i == 1 else pred1.append('Affected') for i in predictions1]\n",
    "print(pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T15:41:06.488288200Z",
     "start_time": "2023-12-03T15:41:06.319883900Z"
    }
   },
   "outputs": [],
   "source": [
    "images_xyz = [xyz_set[0][0]]\n",
    "            \n",
    "prediction_xyz = pred1[0:9]\n",
    "final_xyz_pred = zip(images_xyz,prediction_xyz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T15:41:06.765657700Z",
     "start_time": "2023-12-03T15:41:06.488288200Z"
    }
   },
   "outputs": [],
   "source": [
    "def pre_visualization(data, predictions1):\n",
    "    \n",
    "    for image,pred in final_xyz_pred:\n",
    "        plt.imshow(image.reshape(224,224), cmap = 'gray')\n",
    "        plt.title(\"Model's Prediction: \" + str(pred))\n",
    "        plt.show()\n",
    "        \n",
    "pre_visualization(images_xyz,prediction_xyz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section-two\"></a>\n",
    "### CAM - VISUALIZATION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T15:41:06.776891300Z",
     "start_time": "2023-12-03T15:41:06.771880900Z"
    },
    "execution": {
     "iopub.execute_input": "2021-06-15T20:58:06.247782Z",
     "iopub.status.busy": "2021-06-15T20:58:06.247330Z",
     "iopub.status.idle": "2021-06-15T20:58:06.257351Z",
     "shell.execute_reply": "2021-06-15T20:58:06.256325Z",
     "shell.execute_reply.started": "2021-06-15T20:58:06.247750Z"
    }
   },
   "outputs": [],
   "source": [
    "##%% IMPORTING LIBRARIES\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.cm as cm\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code adapted from: https://keras.io/examples/vision/grad_cam/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T15:41:06.918228400Z",
     "start_time": "2023-12-03T15:41:06.776891300Z"
    },
    "execution": {
     "iopub.execute_input": "2021-06-15T20:58:12.553932Z",
     "iopub.status.busy": "2021-06-15T20:58:12.553552Z",
     "iopub.status.idle": "2021-06-15T20:58:12.565108Z",
     "shell.execute_reply": "2021-06-15T20:58:12.563559Z",
     "shell.execute_reply.started": "2021-06-15T20:58:12.553888Z"
    }
   },
   "outputs": [],
   "source": [
    "layer_names = [layer.name for layer in keras_model.layers]\n",
    "layer_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T15:41:07.012241100Z",
     "start_time": "2023-12-03T15:41:06.871318800Z"
    },
    "execution": {
     "iopub.execute_input": "2021-06-15T20:58:21.952977Z",
     "iopub.status.busy": "2021-06-15T20:58:21.952553Z",
     "iopub.status.idle": "2021-06-15T20:58:21.970031Z",
     "shell.execute_reply": "2021-06-15T20:58:21.968840Z",
     "shell.execute_reply.started": "2021-06-15T20:58:21.952943Z"
    }
   },
   "outputs": [],
   "source": [
    "##%% CREATING THE HEATMAP FROM THE LAYERS' ACTIVATIONS\n",
    "\n",
    "img_size = (224, 224)\n",
    "layer_names=[layer.name for layer in keras_model.layers]\n",
    "\n",
    "last_conv_layer_name = 'conv2d_15'\n",
    "classifier_layer_names = [\n",
    "    'max_pooling2d_7',\n",
    "    'flatten_3',\n",
    "    'dense_9',\n",
    "    'dropout_6',\n",
    "    'dense_10',\n",
    "    'dropout_7',\n",
    "    'dense_11']\n",
    "\n",
    "def make_gradcam_heatmap(\n",
    "    img_array, model, last_conv_layer_name, classifier_layer_names\n",
    "):\n",
    "    \n",
    "    #img_array = test_set[0][8]\n",
    "    img_array = img_array.reshape(1,224,224,1)\n",
    "    img_array = img_array[:1]\n",
    "    \n",
    "    # First, we create a model that maps the input image to the activations\n",
    "    # of the last conv layer\n",
    "    last_conv_layer = model.get_layer(last_conv_layer_name)\n",
    "    last_conv_layer_model = keras.Model(model.inputs, last_conv_layer.output)\n",
    "\n",
    "    # Second, we create a model that maps the activations of the last conv\n",
    "    # layer to the final class predictions\n",
    "    classifier_input = keras.Input(shape=last_conv_layer.output.shape[1:])\n",
    "    x = classifier_input\n",
    "    for layer_name in classifier_layer_names:\n",
    "        x = model.get_layer(layer_name)(x)\n",
    "    classifier_model = keras.Model(classifier_input, x)\n",
    "\n",
    "    # Then, we compute the gradient of the top predicted class for our input image\n",
    "    # with respect to the activations of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Compute activations of the last conv layer and make the tape watch it\n",
    "        last_conv_layer_output = last_conv_layer_model(img_array)\n",
    "        tape.watch(last_conv_layer_output)\n",
    "        # Compute class predictions\n",
    "        preds = classifier_model(last_conv_layer_output)\n",
    "        top_pred_index = tf.argmax(preds[0])\n",
    "        top_class_channel = preds[:, top_pred_index]\n",
    "\n",
    "    # This is the gradient of the top predicted class with regard to\n",
    "    # the output feature map of the last conv layer\n",
    "    grads = tape.gradient(top_class_channel, last_conv_layer_output)\n",
    "\n",
    "    # This is a vector where each entry is the mean intensity of the gradient\n",
    "    # over a specific feature map channel\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1,2))\n",
    "\n",
    "    # We multiply each channel in the feature map array\n",
    "    # by \"how important this channel is\" with regard to the top predicted class\n",
    "    last_conv_layer_output = last_conv_layer_output.numpy()[0]\n",
    "    pooled_grads = pooled_grads.numpy()\n",
    "    for i in range(pooled_grads.shape[-1]):\n",
    "        last_conv_layer_output[:, :, i] *= pooled_grads[i]\n",
    "\n",
    "    # The channel-wise mean of the resulting feature map\n",
    "    # is our heatmap of class activation\n",
    "    heatmap = np.mean(last_conv_layer_output, axis=-1)\n",
    "\n",
    "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
    "    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)\n",
    "    return heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T15:41:07.131832900Z",
     "start_time": "2023-12-03T15:41:07.012241100Z"
    },
    "execution": {
     "iopub.execute_input": "2021-06-15T20:58:27.456020Z",
     "iopub.status.busy": "2021-06-15T20:58:27.455629Z",
     "iopub.status.idle": "2021-06-15T20:58:27.466324Z",
     "shell.execute_reply": "2021-06-15T20:58:27.464984Z",
     "shell.execute_reply.started": "2021-06-15T20:58:27.455986Z"
    }
   },
   "outputs": [],
   "source": [
    "##%% DEFINING A FUNCTION TO DISPLAY THE HEATMAP ON THE REAL IMAGE\n",
    "\n",
    "def display(heatmap, img):\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    # We use jet colormap to colorize heatmap\n",
    "    jet = cm.get_cmap(\"jet\")\n",
    "\n",
    "    # We use RGB values of the colormap\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "    # We create an image with RGB colorized heatmap\n",
    "    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[1]))\n",
    "    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n",
    "    \n",
    "    # Superimpose the heatmap on original image\n",
    "    superimposed_img = jet_heatmap * 0.005 + img.reshape(224,224,1)  #img_array.reshape(224,224,1)\n",
    "    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n",
    "    \n",
    "    return superimposed_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T15:41:12.249642500Z",
     "start_time": "2023-12-03T15:41:07.137404Z"
    },
    "execution": {
     "iopub.execute_input": "2021-06-15T20:58:32.463934Z",
     "iopub.status.busy": "2021-06-15T20:58:32.463562Z",
     "iopub.status.idle": "2021-06-15T20:58:38.040017Z",
     "shell.execute_reply": "2021-06-15T20:58:38.037462Z",
     "shell.execute_reply.started": "2021-06-15T20:58:32.463902Z"
    }
   },
   "outputs": [],
   "source": [
    "##%% OBSERVING THE RAW IMAGE, THE HEATMAP AND THE SUPERIMPOSED IMAGES TOGETHER\n",
    "\n",
    "for img in images10:\n",
    "    heatmap = make_gradcam_heatmap(img,\n",
    "                                   keras_model,\n",
    "                                   last_conv_layer_name,\n",
    "                                   classifier_layer_names)\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize= (10,5))\n",
    "    \n",
    "    ax1.imshow(img.reshape(224,224), cmap = 'gray')\n",
    "    ax1.set_title('Raw MRI image')\n",
    "    ax2.matshow(heatmap)\n",
    "    ax3.imshow(display(heatmap,img))\n",
    "    ax3.set_title('Superimposed Activation Heatmap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T15:44:04.397197Z",
     "start_time": "2023-12-03T15:44:03.074928600Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "for img in images_xyz:\n",
    "    heatmap = make_gradcam_heatmap(img,\n",
    "                                   keras_model,\n",
    "                                   last_conv_layer_name,\n",
    "                                   classifier_layer_names)\n",
    "    fig, (ax4, ax5, ax6) = plt.subplots(1,3, figsize= (10,5))\n",
    "    \n",
    "    ax4.imshow(img.reshape(224,224), cmap = 'gray')\n",
    "    ax4.set_title('Raw MRI image')\n",
    "    ax5.matshow(heatmap)\n",
    "    ax6.imshow(display(heatmap,img))\n",
    "    ax6.set_title('Superimposed Activation Heatmap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:detect]",
   "language": "python",
   "name": "conda-env-detect-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
